{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pylab\n",
    "import sys\n",
    "# making sure the dl4mt module is on the path \n",
    "# -- this path depends upon the location where the notebook is running\n",
    "# here it is assumed to be the day1/ directory\n",
    "sys.path.append('../..')\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../dl4mt/mlp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../dl4mt/mlp.py\n",
    "# Uncomment to save this cell to file in order to import it in later notebooks\n",
    "\n",
    "# construct an MLP graph using theano, then train and evaluate using static features\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "# this is our logistic regression class, created and saved in the LogisticRegression notebook\n",
    "from dl4mt.logistic_regression import LogisticRegression\n",
    "\n",
    "\"\"\"\n",
    " Most of this class was taken from the lisa-lab deeplearning tutorials \n",
    " -- https://github.com/lisa-lab/DeepLearningTutorials\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, input, n_in, n_out, W=None, b=None,\n",
    "                 activation=T.tanh):\n",
    "        \"\"\"\n",
    "        Typical hidden layer of a MLP: units are fully-connected and have\n",
    "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
    "        and the bias vector b is of shape (n_out,).\n",
    "\n",
    "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
    "\n",
    "        :type rng: numpy.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "\n",
    "        :type input: theano.tensor.dmatrix\n",
    "        :param input: a symbolic tensor of shape (n_examples, n_in)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: dimensionality of input\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of hidden units\n",
    "\n",
    "        :type activation: theano.Op or function\n",
    "        :param activation: Non linearity to be applied in the hidden\n",
    "                           layer\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "\n",
    "        # `W` is initialized with `W_values` which is uniformely sampled\n",
    "        # from sqrt(-6./(n_in+n_hidden)) and sqrt(6./(n_in+n_hidden))\n",
    "        # for tanh activation function\n",
    "        # the output of uniform if converted using asarray to dtype\n",
    "        # theano.config.floatX so that the code is runable on GPU\n",
    "        # Note : optimal initialization of weights is dependent on the\n",
    "        #        activation function used (among other things).\n",
    "        #        For example, results presented in [Xavier10] suggest that you\n",
    "        #        should use 4 times larger initial weights for sigmoid\n",
    "        #        compared to tanh\n",
    "        #        We have no info for other function, so we use the same as\n",
    "        #        tanh.\n",
    "        if W is None:\n",
    "            W_values = numpy.asarray(\n",
    "                rng.uniform(\n",
    "                    low=-numpy.sqrt(6. / (n_in + n_out)),\n",
    "                    high=numpy.sqrt(6. / (n_in + n_out)),\n",
    "                    size=(n_in, n_out)\n",
    "                ),\n",
    "                dtype=theano.config.floatX\n",
    "            )\n",
    "            if activation == theano.tensor.nnet.sigmoid:\n",
    "                W_values *= 4\n",
    "\n",
    "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
    "\n",
    "        if b is None:\n",
    "            b_values = numpy.zeros((n_out,), dtype=theano.config.floatX)\n",
    "            b = theano.shared(value=b_values, name='b', borrow=True)\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        lin_output = T.dot(input, self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if activation is None\n",
    "            else activation(lin_output)\n",
    "        )\n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "    \"\"\"Multi-Layer Perceptron Class\n",
    "\n",
    "    A multilayer perceptron is a feedforward artificial neural network model\n",
    "    that has one layer or more of hidden units and nonlinear activations.\n",
    "    Intermediate layers usually have as activation function tanh or the\n",
    "    sigmoid function (defined here by a ``HiddenLayer`` class)  while the\n",
    "    top layer is a softmax layer (defined here by a ``LogisticRegression``\n",
    "    class).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, input, n_in, n_hidden, n_out):\n",
    "        \"\"\"Initialize the parameters for the multilayer perceptron\n",
    "\n",
    "        :type rng: numpy.random.RandomState\n",
    "        :param rng: a random number generator used to initialize weights\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: symbolic variable that describes the input of the\n",
    "        architecture (one minibatch)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: number of input units, the dimension of the space in\n",
    "        which the datapoints lie\n",
    "\n",
    "        :type n_hidden: int\n",
    "        :param n_hidden: number of hidden units\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of output units, the dimension of the space in\n",
    "        which the labels lie\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Since we are dealing with a one hidden layer MLP, this will translate\n",
    "        # into a HiddenLayer with a tanh activation function connected to the\n",
    "        # LogisticRegression layer; the activation function can be replaced by\n",
    "        # sigmoid or any other nonlinear function\n",
    "        self.hiddenLayer = HiddenLayer(\n",
    "            rng=rng,\n",
    "            input=input,\n",
    "            n_in=n_in,\n",
    "            n_out=n_hidden,\n",
    "            activation=T.tanh\n",
    "        )\n",
    "\n",
    "        # The logistic regression layer gets as input the hidden units\n",
    "        # of the hidden layer\n",
    "        self.logRegressionLayer = LogisticRegression(\n",
    "            input=self.hiddenLayer.output,\n",
    "            n_in=n_hidden,\n",
    "            n_out=n_out\n",
    "        )\n",
    "        \n",
    "        # alias to logRegressionLayer.y_pred to provide a consistent interface to our models\n",
    "        self.y_pred = self.logRegressionLayer.y_pred\n",
    "\n",
    "        # L1 norm\n",
    "        self.L1 = (\n",
    "            abs(self.hiddenLayer.W).sum()\n",
    "            + abs(self.logRegressionLayer.W).sum()\n",
    "        )\n",
    "\n",
    "        # L2 norm\n",
    "        self.L2_sqr = (\n",
    "            (self.hiddenLayer.W ** 2).sum()\n",
    "            + (self.logRegressionLayer.W ** 2).sum()\n",
    "        )\n",
    "\n",
    "        # negative log likelihood of the MLP is given by the negative\n",
    "        # log likelihood of the output of the model, computed in the\n",
    "        # logistic regression layer\n",
    "        self.negative_log_likelihood = (\n",
    "            self.logRegressionLayer.negative_log_likelihood\n",
    "        )\n",
    "        # same holds for the function computing the number of errors\n",
    "        self.errors = self.logRegressionLayer.errors\n",
    "\n",
    "        # the parameters of the model are the parameters of the two layer it is\n",
    "        # made out of\n",
    "        self.params = self.hiddenLayer.params + self.logRegressionLayer.params\n",
    "\n",
    "        # keep track of model input -- this will be useful for creating theano functions\n",
    "        self.input = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import timeit\n",
    "\n",
    "from dl4mt.mlp import MLP\n",
    "\n",
    "\n",
    "def initialize_mlp(train_dataset, dev_dataset, learning_rate=0.01, L1_reg=0.00, L2_reg=0.0001, \n",
    "                   batch_size=10, n_hidden=500):\n",
    "    \n",
    "    \"\"\"Intialize the functions and parameters needed to train a multilayer perceptron\n",
    "\n",
    "    :type train_dataset: tuple\n",
    "    :param train_dataset: a tuple consisting of (X,y) for the training dataset\n",
    "                          (X and y are theano shared variables)\n",
    "                          \n",
    "    :type dev_dataset: tuple\n",
    "    :param dev_dataset: a tuple consisting of (X,y) for the dev/validation dataset\n",
    "                        (X and y are theano shared variables)                      \n",
    "    \n",
    "    :type learning_rate: float\n",
    "    :param learning_rate: learning rate used (factor for the stochastic\n",
    "                          gradient)\n",
    "\n",
    "\n",
    "    :type n_out: int\n",
    "    :param batch_size: the number of output \"classes\"\n",
    "\n",
    "    :type L1_reg: float\n",
    "    :param L1_reg: L1-norm's weight when added to the cost (see\n",
    "    regularization)\n",
    "\n",
    "    :type L2_reg: float\n",
    "    :param L2_reg: L2-norm's weight when added to the cost (see\n",
    "    regularization)\n",
    "\n",
    "    :type batch_size: int\n",
    "    :param batch_size: the minibatch size for training and validation \n",
    "\n",
    "    :type n_hidden: int\n",
    "    :param batch_size: the size of the hidden layer\n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "    train_set_x, train_set_y = train_dataset\n",
    "    valid_set_x, valid_set_y = dev_dataset\n",
    "\n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lscalar()  # index to a [mini]batch\n",
    "    x = T.matrix('x')  # the data is presented as rasterized images\n",
    "    y = T.ivector('y')  # the labels are presented as 1D vector of\n",
    "                        # [int] labels\n",
    "\n",
    "    rng = numpy.random.RandomState(1234)\n",
    "    \n",
    "    # TODO: move these into the parameterization of the training function\n",
    "    n_in = train_set_x.get_value().shape[1]\n",
    "    n_out = 12\n",
    "    \n",
    "    # construct the MLP class\n",
    "    classifier = MLP(\n",
    "        rng=rng,\n",
    "        input=x,\n",
    "        n_in=n_in,\n",
    "        n_hidden=n_hidden,\n",
    "        n_out=n_out\n",
    "    )\n",
    "\n",
    "    # the cost we minimize during training is the negative log likelihood of\n",
    "    # the model plus the regularization terms (L1 and L2); cost is expressed\n",
    "    # here symbolically\n",
    "    cost = (\n",
    "        classifier.negative_log_likelihood(y)\n",
    "        + L1_reg * classifier.L1\n",
    "        + L2_reg * classifier.L2_sqr\n",
    "    )\n",
    "\n",
    "    validate_model_func = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size:(index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size:(index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # compute the gradient of cost with respect to theta (sotred in params)\n",
    "    # the resulting gradients will be stored in a list gparams\n",
    "    gparams = [T.grad(cost, param) for param in classifier.params]\n",
    "\n",
    "    # specify how to update the parameters of the model as a list of\n",
    "    # (variable, update expression) pairs\n",
    "    updates = [\n",
    "        (param, param - learning_rate * gparam)\n",
    "        for param, gparam in zip(classifier.params, gparams)\n",
    "    ]\n",
    "\n",
    "    # compiling a Theano function `train_model` that returns the cost, but\n",
    "    # in the same time updates the parameters of the model based on the rules\n",
    "    # defined in `updates`\n",
    "    train_model_func = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return (classifier, train_model_func, validate_model_func, n_train_batches, n_valid_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, minibatch 200/200, validation error 51.240000 %\n",
      "epoch 1, average training cost 1.70\n",
      "epoch 2, minibatch 200/200, validation error 43.420000 %\n",
      "epoch 2, average training cost 1.25\n",
      "epoch 3, minibatch 200/200, validation error 38.330000 %\n",
      "epoch 3, average training cost 1.04\n",
      "epoch 4, minibatch 200/200, validation error 34.620000 %\n",
      "epoch 4, average training cost 0.91\n",
      "epoch 5, minibatch 200/200, validation error 31.020000 %\n",
      "epoch 5, average training cost 0.82\n",
      "epoch 6, minibatch 200/200, validation error 28.330000 %\n",
      "epoch 6, average training cost 0.76\n",
      "epoch 7, minibatch 200/200, validation error 26.640000 %\n",
      "epoch 7, average training cost 0.71\n",
      "epoch 8, minibatch 200/200, validation error 25.290000 %\n",
      "epoch 8, average training cost 0.67\n",
      "epoch 9, minibatch 200/200, validation error 24.410000 %\n",
      "epoch 9, average training cost 0.63\n",
      "epoch 10, minibatch 200/200, validation error 23.690000 %\n",
      "epoch 10, average training cost 0.60\n",
      "Optimization complete!\n",
      "Best validation score: 23.690000 %\n"
     ]
    }
   ],
   "source": [
    "# TODO: allow user to load another distributed representation for comparison, such as PCA\n",
    "import os\n",
    "\n",
    "from dl4mt.datasets import prep_dataset\n",
    "from dl4mt.training import train_model\n",
    "\n",
    "# location of our datasets\n",
    "DATASET_LOCATION = '../../datasets/'\n",
    "\n",
    "# the pos dataset consists of windows around words\n",
    "POS_DATASET_NAME = 'brown_pos_dataset.hdf5'\n",
    "POS_DATASET_PATH = os.path.join(DATASET_LOCATION, POS_DATASET_NAME)\n",
    "WORD_BY_WORD_MATRIX = 'brown.word-by-word.normalized.npy'\n",
    "VECTOR_INDEX_PATH = os.path.join(DATASET_LOCATION, WORD_BY_WORD_MATRIX)\n",
    "\n",
    "CUTOFF = 10000\n",
    "  \n",
    "train_dataset = prep_dataset(POS_DATASET_PATH, VECTOR_INDEX_PATH, which_sets=['train'], cutoff=CUTOFF)\n",
    "dev_dataset = prep_dataset(POS_DATASET_PATH, VECTOR_INDEX_PATH, which_sets=['dev'], cutoff=CUTOFF)\n",
    "\n",
    "# initialize the MLP\n",
    "initialization_data = initialize_mlp(train_dataset, dev_dataset, learning_rate=0.01, batch_size=50)\n",
    "\n",
    "classifier, train_model_func, validate_model_func, n_train_batches, n_valid_batches = initialization_data\n",
    "\n",
    "# train the MLP model\n",
    "train_model(train_model_func, n_train_batches, validate_model=validate_model_func,\n",
    "            n_valid_batches=n_valid_batches, training_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79869999999999997"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cPickle\n",
    "from dl4mt.predict import predict\n",
    "\n",
    "test_dataset = prep_dataset(POS_DATASET_PATH, VECTOR_INDEX_PATH, which_sets=['test'], cutoff=CUTOFF, cast_y=False)\n",
    "\n",
    "test_X, test_y = test_dataset\n",
    "test_y = test_y.get_value().astype('int32')\n",
    "predictions = predict(classifier, test_X.get_value())\n",
    "\n",
    "CORPUS_INDICES = 'brown_pos_dataset.indices'\n",
    "# Indexes for mapping words and tags <--> ints\n",
    "with open(os.path.join(DATASET_LOCATION, CORPUS_INDICES)) as indices_file:\n",
    "    corpus_indices = cPickle.load(indices_file)\n",
    "\n",
    "# map tag ids back to strings\n",
    "y_test_actual = [corpus_indices['idx2tag'][tag_idx] for tag_idx in test_y]\n",
    "y_test_hat = [corpus_indices['idx2tag'][tag_idx] for tag_idx in predictions]\n",
    "\n",
    "# Quick Evaluation\n",
    "sum([y==p for y,p in zip(predictions, test_y)]) / float(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAJJCAYAAADGP62VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzQbNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103d7f790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dl4mt.confusion_matrix import plot_confusion_matrix\n",
    "\n",
    "# get class names\n",
    "class_names = list(set(y_test_actual))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test_actual, y_test_hat, labels=class_names)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, class_names, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Challenges: \n",
    "(1)\n",
    "- change the MLP class to allow adding multiple hidden layers\n",
    "- how can you leverage the HiddenLayer class to do that? \n",
    "- how does the performance of the model change as you add layers?\n",
    "- hint: run the code in theano_autoencoder.ipynb, then take a look at stacked_autoencoder.ipynb, and understand how multiple hidden layers are created there \n",
    "\n",
    "(2)\n",
    "- compare performance with different regularization weights\n",
    "- what effect does setting the L2 regularization weight very low or very high have on the model performance?\n",
    "\n",
    "(3) \n",
    "- make the final hidden layer (before the Logistic layer) of your model have only two dimensions. Add a function to the MLP class which outputs the 2D embedding for a given X, then make a scatter plot of some datapoints to see if you're getting good separation of the different classes. \n",
    "- hint -- take a look at theano_autoencoder.ipynb and stacked_autoencoder.ipynb for some plotting code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
